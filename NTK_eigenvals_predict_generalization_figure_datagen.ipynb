{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NTK_eigenvals_predict_generalization_figure_datagen",
      "provenance": [],
      "collapsed_sections": [
        "09s0S9rwlTwa",
        "XIN6v-M6qS_y",
        "uVob1X2YqZjO",
        "6HiiuGHUvlVy",
        "vOgjKMLIYqSi",
        "Gice3m_nkEX1",
        "uNKcTqLbpqmU"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yav5j0-llRPf"
      },
      "source": [
        "# Imports and installs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcQQq2580pFX"
      },
      "source": [
        "In this notebook, we generate and save the experimental data for all figures. This might take several days to run. Each figure's data can be generated independently by running the respective cells, and a given figure can be rendered without generating data for other figures.\n",
        "\n",
        "This notebook is designed to be run in Google Colab, in which the path ```/content``` exists. To use this notebook outside of Colab, only self-evident changes to the Imports and Installs section should be necessary. This first cell isn't required if ```neural_tangents``` and ```eigenlearning``` are already installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "freeanHRdMte"
      },
      "source": [
        "!pip install -q git+https://www.github.com/google/neural-tangents\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "if os.path.isdir('/content/eigenlearning'):\n",
        "  !rm -r '/content/eigenlearning'\n",
        "!git clone -q https://github.com/james-simon/eigenlearning.git\n",
        "sys.path.insert(0,'/content/eigenlearning')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74TQWvIHig28"
      },
      "source": [
        "import json\n",
        "import math\n",
        "\n",
        "import jax.numpy as np\n",
        "import jax.random as random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTt6JdUkdRwi"
      },
      "source": [
        "from utils import get_net_fns, net_predictions\n",
        "from measures import learning_measure_predictions, learning_measure_statistics, find_C\n",
        "from unit_circle import unit_circle_eigenvalues, get_unit_circle_dataset\n",
        "from hypercube import hypercube_eigenvalues\n",
        "from hypersphere import hypersphere_eigenvalues"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ahFK52kf3_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f39e252-919a-4fd0-a567-838b50b7be6c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1S3AbJd1mIs"
      },
      "source": [
        "main_dir = '/content/drive/Shareddrives/Eigenlearning'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xubEhWeX1oV9"
      },
      "source": [
        "# Generate data for figures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fycSBHSgSM4u"
      },
      "source": [
        "## Illustrative toy problem plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsP5sRtTSM4x"
      },
      "source": [
        "for dir in [main_dir+'/A', main_dir+'/A/circle']:\n",
        "  if not os.path.exists(dir):\n",
        "      os.makedirs(dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNSDHuEaSM4x"
      },
      "source": [
        "net_fns = get_net_fns(width=500, d_out=1, n_hidden_layers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpZgawbGUZve"
      },
      "source": [
        "M = 256\n",
        "ks = [2, 7]\n",
        "\n",
        "lambdas, mults = unit_circle_eigenvalues(net_fns[2], M), 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVB3-_fwSM4y"
      },
      "source": [
        "exp_params = {\n",
        "    'domain': 'circle',\n",
        "    'M': M,\n",
        "    'n': None,\n",
        "    'f_terms': None,\n",
        "    'g_terms':None,\n",
        "    'n_epochs': 10000,\n",
        "    'lr': .5,\n",
        "    'stop_mse': 10**-7,\n",
        "    'print_every': None,\n",
        "    'n_trials': 30,\n",
        "    'lambdas': lambdas,\n",
        "    'mults': mults,\n",
        "    'seed': 2,\n",
        "    'pred_type': 'both'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuZEnhQo7mr6"
      },
      "source": [
        "### Unit Circle - example runs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNlaw21H7rGd"
      },
      "source": [
        "ns = [2**2, 2**4, 2**6]\n",
        "\n",
        "subkey = np.array([0,2],dtype='uint32')\n",
        "index_bank = random.choice(subkey, np.arange(0, M, 1), shape=[M], replace=False)\n",
        "\n",
        "interpolation_plot_datasets = {}\n",
        "for k in ks:\n",
        "  (test_thetas, test_X, test_y) = get_unit_circle_dataset(M, [{(k,'c') : 2**(-.5)}])\n",
        "  test_y = test_y[0]\n",
        "  for n in ns:\n",
        "    interpolation_plot_datasets[(k,n)] = [(test_thetas[index_bank[:n]], test_X[index_bank[:n]], test_y[index_bank[:n]]), (test_thetas, test_X, test_y)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3VCiq0MBacv"
      },
      "source": [
        "results_int = {'datasets':{}, 'y_hats':{}}\n",
        "\n",
        "for k in ks:\n",
        "  for n in ns:\n",
        "    (train_thetas, train_X, train_y), (test_thetas, test_X, test_y) = interpolation_plot_datasets[(k,n)]\n",
        "    net_preds = net_predictions(net_fns, ((train_X, train_y),(test_X,test_y)), exp_params['n_epochs'], exp_params['lr'], subkey, stop_mse=exp_params['stop_mse'])\n",
        "\n",
        "    results_int['datasets'][str(k) + ',' + str(n)] = [[vals.tolist() for vals in valset] for valset in interpolation_plot_datasets[(k,n)]]\n",
        "    results_int['y_hats'][str(k) + ',' + str(n)] = net_preds['test_preds'].tolist()\n",
        "\n",
        "    with open(main_dir+'/A/circle/results_int.json', 'w') as file:\n",
        "      json.dump(results_int, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF4FXQRESM4y"
      },
      "source": [
        "### Unit Circle - experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKxHlZaGSM4y"
      },
      "source": [
        "g_terms = [{(5,'c') : 1}]\n",
        "exp_params['g_terms'] = g_terms\n",
        "\n",
        "ns_exp = [0] + [2**i for i in range(round(math.log2(M)) + 1)]\n",
        "ns_th = list(np.linspace(0, 1, 10, endpoint=False)) + list(np.logspace(0, math.log10(M), 50))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFjpCEKJSM4y"
      },
      "source": [
        "##### Unit circle theory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SAsAZ7xSM4y",
        "outputId": "1ad1a399-cb85-4bfe-9463-3e6884b678ac"
      },
      "source": [
        "results_th = {}\n",
        "\n",
        "for n in ns_th:\n",
        "  for k in ks:\n",
        "    exp_params['f_terms'] = {(k, 'c') : 2**(-.5)}\n",
        "    exp_params['n'] = n\n",
        "    results = learning_measure_predictions(net_fns[2], **exp_params)\n",
        "    results['g_coeffs'][0] = list(results['g_coeffs'][0])\n",
        "    results['g_coeffs'][0][1] = results['g_coeffs'][0][1].real  # squelch a little imaginary numerical error\n",
        "    results_th[str(k) + ',' + '%.3f'%n] = results\n",
        "    with open(main_dir+'/A/circle/results_th.json', 'w') as file:\n",
        "      json.dump(results_th, file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
            "  improvement from the last ten iterations.\n",
            "  warnings.warn(msg, RuntimeWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d116ZU4JSM4z"
      },
      "source": [
        "##### Unit circle experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J50LusBHSM4z"
      },
      "source": [
        "results_exp = {}\n",
        "\n",
        "for n in ns_exp:\n",
        "  for k in ks:\n",
        "    print(f'predicting for {(k, n)}')\n",
        "    exp_params['f_terms'] = {(k, 'c') : 2**(-.5)}\n",
        "    exp_params['n'] = n\n",
        "    results = learning_measure_statistics(net_fns, **exp_params)\n",
        "    results_exp[str(k) + ',' + str(n)] = results\n",
        "    with open(main_dir+'/A/circle/results_exp.json', 'w') as file:\n",
        "      json.dump(results_exp, file)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09s0S9rwlTwa"
      },
      "source": [
        "## Learnability curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNjW6iBhofUt"
      },
      "source": [
        "for dir in [main_dir+'/B', main_dir+'/B/circle', main_dir+'/B/hypercube', main_dir+'/B/hypersphere']:\n",
        "  if not os.path.exists(dir):\n",
        "      os.makedirs(dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vYuk_oTe3oa"
      },
      "source": [
        "net_fns = get_net_fns(width=500, d_out=1, n_hidden_layers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIN6v-M6qS_y"
      },
      "source": [
        "### Unit Circle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yffojvRsmDi2"
      },
      "source": [
        "M = 2**8\n",
        "\n",
        "ks = [0, 2, 5, 10]\n",
        "\n",
        "ns_exp = [0] + [2**i for i in range(round(math.log2(M)) + 1)]\n",
        "ns_th = list(np.linspace(0, 1, 10, endpoint=False)) + list(np.logspace(0, math.log10(M), 50))\n",
        "\n",
        "lambdas, mults = unit_circle_eigenvalues(net_fns[2], M), 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS0UyKknnUnL"
      },
      "source": [
        "exp_params = {\n",
        "    'domain': 'circle',\n",
        "    'M': M,\n",
        "    'n': None,\n",
        "    'f_terms': None,\n",
        "    'g_terms': [],\n",
        "    'n_epochs': 10000,\n",
        "    'lr': .5,\n",
        "    'stop_mse': 10**-5,\n",
        "    'print_every': None,\n",
        "    'n_trials': 30,\n",
        "    'lambdas': lambdas,\n",
        "    'mults': mults,\n",
        "    'seed': 1,\n",
        "    'pred_type': 'both'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baC6LCA432o2"
      },
      "source": [
        "##### Unit circle theory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPKQAglDdv2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "727bcb96-b597-4837-c7a3-1e9593e00172"
      },
      "source": [
        "results_th = {}\n",
        "\n",
        "for n in ns_th:\n",
        "  # print(f'predicting for n = {n}')\n",
        "  for k in ks:\n",
        "    exp_params['f_terms'] = {(k, 'c') : 1}\n",
        "    exp_params['n'] = n\n",
        "    results = learning_measure_predictions(net_fns[2], **exp_params)\n",
        "    results_th[str(k) + ',' + '%.3f'%n] = results\n",
        "    with open(main_dir+'/B/circle/results_th.json', 'w') as file:\n",
        "      json.dump(results_th, file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
            "  improvement from the last ten iterations.\n",
            "  warnings.warn(msg, RuntimeWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-ek6dzj343S"
      },
      "source": [
        "##### Unit circle experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WX9-vrqkb6Q"
      },
      "source": [
        "results_exp = {}\n",
        "\n",
        "for n in ns_exp:\n",
        "  for k in ks:\n",
        "    print(f'predicting for {(k, n)}')\n",
        "    exp_params['f_terms'] = {(k, 'c') : 1}\n",
        "    exp_params['n'] = n\n",
        "    results = learning_measure_statistics(net_fns, **exp_params)\n",
        "    results_exp[str(k) + ',' + str(n)] = results\n",
        "    with open(main_dir+'/B/circle/results_exp.json', 'w') as file:\n",
        "      json.dump(results_exp, file)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVob1X2YqZjO"
      },
      "source": [
        "### Hypercube"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUQmJpiuqZjP"
      },
      "source": [
        "d = 8\n",
        "\n",
        "ks = [0, 1, 3, 8]\n",
        "\n",
        "ns_exp = [0] + [2**i for i in range(d + 1)]\n",
        "ns_th = list(np.linspace(0, 1, 10, endpoint=False)) + list(np.logspace(0, math.log10(2**d), 50))\n",
        "\n",
        "lambdas, mults = hypercube_eigenvalues(net_fns[2], d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71oB6PqaqZjd"
      },
      "source": [
        "exp_params = {\n",
        "    'domain': 'hypercube',\n",
        "    'd': d,\n",
        "    'n': None,\n",
        "    'f_terms': None,\n",
        "    'g_terms': [],\n",
        "    'n_epochs': 10000,\n",
        "    'lr': .5,\n",
        "    'stop_mse': 10**-5,\n",
        "    'print_every': None,\n",
        "    'n_trials': 30,\n",
        "    'lambdas': lambdas,\n",
        "    'mults': mults,\n",
        "    'seed': 1,\n",
        "    'pred_type': 'both'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNQ1S56p3tK0"
      },
      "source": [
        "##### Hypercube theory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl7uKaPBqZje",
        "outputId": "9fc24a1a-77e2-4a2b-e1a9-2a60d524dd48"
      },
      "source": [
        "results_th = {}\n",
        "\n",
        "for n in ns_th:\n",
        "  for k in ks:\n",
        "    # print(f'predicting for n = {n}')\n",
        "    exp_params['f_terms'] = {k : 1}\n",
        "    exp_params['n'] = n\n",
        "    results = learning_measure_predictions(net_fns[2], **exp_params)\n",
        "    results_th[str(k) + ',' + '%.3f'%n] = results\n",
        "    with open(main_dir+'/B/hypercube/results_th.json', 'w') as file:\n",
        "      json.dump(results_th, file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
            "  improvement from the last ten iterations.\n",
            "  warnings.warn(msg, RuntimeWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOm7OErS3n8g"
      },
      "source": [
        "##### Hypercube experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_IGcZ4oqZjf"
      },
      "source": [
        "results_exp = {}\n",
        "\n",
        "for n in ns_exp:\n",
        "  for k in ks:\n",
        "    print(f'predicting for {(k, n)}')\n",
        "    exp_params['f_terms'] = {k : 1}\n",
        "    exp_params['n'] = n\n",
        "    results = learning_measure_statistics(net_fns, **exp_params)\n",
        "    results_exp[str(k) + ',' + str(n)] = results\n",
        "    with open(main_dir+'/B/hypercube/results_exp.json', 'w') as file:\n",
        "      json.dump(results_exp, file)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HiiuGHUvlVy"
      },
      "source": [
        "### Hypersphere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCUBHabTvlV4"
      },
      "source": [
        "d = 8\n",
        "n_max = 2**8\n",
        "\n",
        "ks = [0, 1, 2, 3, 4, 5]\n",
        "\n",
        "ns_exp = [0] + [2**i for i in range(round(math.log2(n_max)) + 1)]\n",
        "ns_th = list(np.linspace(0, 1, 10, endpoint=False)) + list(np.logspace(0, math.log10(n_max), 50))\n",
        "\n",
        "lambdas, mults = hypersphere_eigenvalues(net_fns[2], d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6nNP6Q1vlV5"
      },
      "source": [
        "exp_params = {\n",
        "    'domain': 'hypersphere',\n",
        "    'd': d,\n",
        "    'n': None,\n",
        "    'n_test': 10**4,\n",
        "    'f_terms': None,\n",
        "    'g_terms': [],\n",
        "    'n_epochs': 10000,\n",
        "    'lr': .5,\n",
        "    'stop_mse': 10**-5,\n",
        "    'print_every': None,\n",
        "    'n_trials': 30,\n",
        "    'lambdas': lambdas,\n",
        "    'mults': mults,\n",
        "    'seed': 1,\n",
        "    'pred_type': 'both'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maCrs_9u3w6M"
      },
      "source": [
        "##### Hypersphere theory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2jPc_rNrtj-"
      },
      "source": [
        "results_th = {}\n",
        "\n",
        "for n in ns_th:\n",
        "  # print(f'predicting for n = {n}')\n",
        "  for k in ks:\n",
        "    exp_params['f_terms'] = {k : 1}\n",
        "    exp_params['n'] = n\n",
        "    results = learning_measure_predictions(net_fns[2], **exp_params)\n",
        "    results_th[str(k) + ',' + '%.3f'%n] = results\n",
        "    with open(main_dir+'/B/hypersphere/results_th.json', 'w') as file:\n",
        "      json.dump(results_th, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfsHiPgu30XK"
      },
      "source": [
        "##### Hypersphere experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWHTiu4TwPx7"
      },
      "source": [
        "results_exp = {}\n",
        "\n",
        "for n in ns_exp:\n",
        "  for k in ks:\n",
        "    print(f'predicting for {(k, n)}')\n",
        "    exp_params['f_terms'] = {k : 1}\n",
        "    exp_params['n'] = n\n",
        "    results = learning_measure_statistics(net_fns, **exp_params)\n",
        "    results_exp[str(k) + ',' + str(n)] = results\n",
        "    with open(main_dir+'/B/hypersphere/results_exp.json', 'w') as file:\n",
        "      json.dump(results_exp, file)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOgjKMLIYqSi"
      },
      "source": [
        "## Universal sigmoidal learnability curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "939wH_-4Yw0H"
      },
      "source": [
        "for dir in [main_dir+'/C', main_dir+'/C/circle', main_dir+'/C/hypercube', main_dir+'/C/hypersphere']:\n",
        "  if not os.path.exists(dir):\n",
        "      os.makedirs(dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0Dh-SZmYw0H"
      },
      "source": [
        "net_fns = get_net_fns(width=500, d_out=1, n_hidden_layers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbIjungZY-HM"
      },
      "source": [
        "### Unit Circle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlT3p6dDY-HM"
      },
      "source": [
        "M = 2**8\n",
        "\n",
        "ks = [0, 1, 2, 3, 4, 5, 6, 7]\n",
        "\n",
        "ns_exp = [2**3, 2**6]\n",
        "\n",
        "lambdas, mults = unit_circle_eigenvalues(net_fns[2], M), 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJSzSNx0Y-HM"
      },
      "source": [
        "exp_params = {\n",
        "    'domain': 'circle',\n",
        "    'M': M,\n",
        "    'n': None,\n",
        "    'f_terms': None,\n",
        "    'g_terms': [],\n",
        "    'n_epochs': 10000,\n",
        "    'lr': .5,\n",
        "    'stop_mse': 10**-5,\n",
        "    'print_every': None,\n",
        "    'n_trials': 30,\n",
        "    'lambdas': lambdas,\n",
        "    'mults': mults,\n",
        "    'seed': 1,\n",
        "    'pred_type': 'both'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN0F9TTQY-HN"
      },
      "source": [
        "##### Unit circle experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l96Q0JvDY-HN"
      },
      "source": [
        "results_exp = {}\n",
        "\n",
        "for n in ns_exp:\n",
        "  for k in ks:\n",
        "    print(f'predicting for {(k, n)}')\n",
        "    exp_params['f_terms'] = {(k, 'c') : 1}\n",
        "    exp_params['n'] = n\n",
        "    results = learning_measure_statistics(net_fns, **exp_params)\n",
        "    results_exp[str(k) + ',' + str(n)] = results\n",
        "    with open(main_dir+'/C/circle/results_exp.json', 'w') as file:\n",
        "      json.dump(results_exp, file)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtbewyuwY-HM"
      },
      "source": [
        "##### Unit circle theory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwz8O1kMY-HM"
      },
      "source": [
        "Cs = {n : find_C(n, lambdas, mults).item() for n in ns_exp}\n",
        "\n",
        "results_th = {\n",
        "    'lambdas' : [float(l) for l in lambdas],\n",
        "    'Cs' : Cs\n",
        "}\n",
        "\n",
        "with open(main_dir+'/C/circle/results_th.json', 'w') as file:\n",
        "  json.dump(results_th, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqAqN5eriaXl"
      },
      "source": [
        "### Hypercube"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2g2rtuZiaXl"
      },
      "source": [
        "d = 8\n",
        "\n",
        "ks = [0, 1, 2, 3, 4, 5, 6]\n",
        "\n",
        "ns_exp = [2**3, 2**6]\n",
        "\n",
        "lambdas, mults = hypercube_eigenvalues(net_fns[2], d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC3A3wHRiaXl"
      },
      "source": [
        "exp_params = {\n",
        "    'domain': 'hypercube',\n",
        "    'd': d,\n",
        "    'n': None,\n",
        "    'f_terms': None,\n",
        "    'g_terms': [],\n",
        "    'n_epochs': 10000,\n",
        "    'lr': .1,\n",
        "    'stop_mse': 10**-5,\n",
        "    'print_every': None,\n",
        "    'n_trials': 30,\n",
        "    'lambdas': lambdas,\n",
        "    'mults': mults,\n",
        "    'seed': 1,\n",
        "    'pred_type': 'both'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4INcsND8iaXm"
      },
      "source": [
        "##### Hypercube experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BfZwTgLiaXm"
      },
      "source": [
        "results_exp = {}\n",
        "\n",
        "for n in ns_exp:\n",
        "  for k in ks:\n",
        "    print(f'predicting for {(k, n)}')\n",
        "    exp_params['f_terms'] = {k : 1}\n",
        "    exp_params['n'] = n\n",
        "    results = learning_measure_statistics(net_fns, **exp_params)\n",
        "    results_exp[str(k) + ',' + str(n)] = results\n",
        "    with open(main_dir+'/C/hypercube/results_exp.json', 'w') as file:\n",
        "      json.dump(results_exp, file)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thPNowf0iaXm"
      },
      "source": [
        "##### Hypercube theory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEiuYBy-iaXm"
      },
      "source": [
        "Cs = {n : find_C(n, lambdas, mults).item() for n in ns_exp}\n",
        "\n",
        "results_th = {\n",
        "    'lambdas' : [float(l) for l in lambdas],\n",
        "    'Cs' : Cs\n",
        "}\n",
        "\n",
        "with open(main_dir+'/C/hypercube/results_th.json', 'w') as file:\n",
        "  json.dump(results_th, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZTLdlUNi_Sl"
      },
      "source": [
        "### Hypersphere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO-kQ0PTi_Sl"
      },
      "source": [
        "d = 8\n",
        "\n",
        "ks = [0, 1, 2, 3, 4, 5, 6, 7]\n",
        "\n",
        "ns_exp = [2**3, 2**6]\n",
        "\n",
        "lambdas, mults = hypersphere_eigenvalues(net_fns[2], d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5UWMHwji_Sm"
      },
      "source": [
        "exp_params = {\n",
        "    'domain': 'hypersphere',\n",
        "    'd': d,\n",
        "    'n': None,\n",
        "    'n_test': 10**4,\n",
        "    'f_terms': None,\n",
        "    'g_terms': [],\n",
        "    'n_epochs': 10000,\n",
        "    'lr': .5,\n",
        "    'stop_mse': 10**-5,\n",
        "    'print_every': None,\n",
        "    'n_trials': 30,\n",
        "    'lambdas': lambdas,\n",
        "    'mults': mults,\n",
        "    'seed': 1,\n",
        "    'pred_type': 'both'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbJm1Q-oi_Sn"
      },
      "source": [
        "##### Hypersphere experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDHBFAV1i_Sn"
      },
      "source": [
        "results_exp = {}\n",
        "\n",
        "for n in ns_exp:\n",
        "  for k in ks:\n",
        "    print(f'predicting for {(k, n)}')\n",
        "    exp_params['f_terms'] = {k : 1}\n",
        "    exp_params['n'] = n\n",
        "    results = learning_measure_statistics(net_fns, **exp_params)\n",
        "    results_exp[str(k) + ',' + str(n)] = results\n",
        "    with open(main_dir+'/C/hypersphere/results_exp.json', 'w') as file:\n",
        "      json.dump(results_exp, file)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWUoURrWi_Sn"
      },
      "source": [
        "##### Hypersphere theory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D5f_Anti_Sn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6721e24-5f69-4c72-8226-735b6611f864"
      },
      "source": [
        "Cs = {n : find_C(n, lambdas, mults).item() for n in ns_exp}\n",
        "\n",
        "results_th = {\n",
        "    'lambdas' : [float(l) for l in lambdas],\n",
        "    'Cs' : Cs\n",
        "}\n",
        "\n",
        "with open(main_dir+'/C/hypersphere/results_th.json', 'w') as file:\n",
        "  json.dump(results_th, file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
            "  improvement from the last ten iterations.\n",
            "  warnings.warn(msg, RuntimeWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gice3m_nkEX1"
      },
      "source": [
        "## Nonmonotonic MSE curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2rmGHpOTN8i"
      },
      "source": [
        "for dir in [main_dir+'/D', main_dir+'/D/circle', main_dir+'/D/hypercube', main_dir+'/D/hypersphere']:\n",
        "  if not os.path.exists(dir):\n",
        "      os.makedirs(dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kxjmx06iTN8j"
      },
      "source": [
        "net_fns = get_net_fns(width=500, d_out=1, n_hidden_layers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYhCsGUtAhu2"
      },
      "source": [
        "### Unit Circle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL7lf6z-Ahu8"
      },
      "source": [
        "M = 256\n",
        "\n",
        "ks = [0, 2, 4, 6]\n",
        "\n",
        "ns_exp = [0, 1, 2, 3, 4, 5, 6, 7]\n",
        "ns_th = list(np.linspace(0, max(ns_exp), 50, endpoint=True))\n",
        "\n",
        "lambdas, mults = unit_circle_eigenvalues(net_fns[2], M), 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrHWE887Ahu8"
      },
      "source": [
        "exp_params = {\n",
        "    'domain': 'circle',\n",
        "    'M': M,\n",
        "    'n': None,\n",
        "    'f_terms': None,\n",
        "    'g_terms': [],\n",
        "    'n_epochs': 10000,\n",
        "    'lr': .5,\n",
        "    'stop_mse': 10**-5,\n",
        "    'print_every': None,\n",
        "    'n_trials': 100,\n",
        "    'lambdas': lambdas,\n",
        "    'mults': mults,\n",
        "    'seed': 2,\n",
        "    'pred_type': 'both'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J09_--mKAhu8"
      },
      "source": [
        "##### Unit circle theory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8HKAc0ZAhu9",
        "outputId": "cd7c33cb-e0d2-4212-ca4f-8e85b3da443e"
      },
      "source": [
        "results_th = {}\n",
        "\n",
        "l_sum = (lambdas*mults).sum().item()\n",
        "l2_sum = (lambdas**2 * mults).sum().item()\n",
        "dE_dn_preds = (l2_sum / l_sum**2 - 2 * lambdas / l_sum)\n",
        "results_th['dE_dn'] = [float(x) for x in dE_dn_preds]\n",
        "\n",
        "for n in ns_th:\n",
        "  # print(f'predicting for n = {n}')\n",
        "  for k in ks:\n",
        "    exp_params['f_terms'] = {(k,'c') : 1}\n",
        "    exp_params['n'] = n\n",
        "    results = learning_measure_predictions(net_fns[2], **exp_params)\n",
        "    results_th[str(k) + ',' + '%.3f'%n] = results\n",
        "    with open(main_dir+'/D/circle/results_th.json', 'w') as file:\n",
        "      json.dump(results_th, file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
            "  improvement from the last ten iterations.\n",
            "  warnings.warn(msg, RuntimeWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mee7K833BMMT"
      },
      "source": [
        "##### Unit circle experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmfoKoGwBMMU"
      },
      "source": [
        "results_exp = {}\n",
        "\n",
        "for n in ns_exp:\n",
        "  for k in ks:\n",
        "    print(f'predicting for {(k, n)}')\n",
        "    exp_params['f_terms'] = {(k,'c') : 1}\n",
        "    exp_params['n'] = n\n",
        "    results = learning_measure_statistics(net_fns, **exp_params)\n",
        "    results_exp[str(k) + ',' + str(n)] = results\n",
        "    with open(main_dir+'/D/circle/results_exp.json', 'w') as file:\n",
        "      json.dump(results_exp, file)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-j4G_NP_Qte"
      },
      "source": [
        "### Hypercube"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jJBm82M_Qtf"
      },
      "source": [
        "d = 6\n",
        "\n",
        "ks = [0, 2, 4, 6]\n",
        "\n",
        "ns_exp = [0, 1, 2, 3, 4, 5, 6, 7]\n",
        "ns_th = list(np.linspace(0, max(ns_exp), 50, endpoint=True))\n",
        "\n",
        "lambdas, mults = hypercube_eigenvalues(net_fns[2], d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8WMCR4s_Qtg"
      },
      "source": [
        "exp_params = {\n",
        "    'domain': 'hypercube',\n",
        "    'd': d,\n",
        "    'n': None,\n",
        "    'f_terms': None,\n",
        "    'g_terms': [],\n",
        "    'n_epochs': 10000,\n",
        "    'lr': .1,\n",
        "    'stop_mse': 10**-5,\n",
        "    'print_every': None,\n",
        "    'n_trials': 100,\n",
        "    'lambdas': lambdas,\n",
        "    'mults': mults,\n",
        "    'seed': 2,\n",
        "    'pred_type': 'both'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkrhfTeY_Qtg"
      },
      "source": [
        "##### Hypercube theory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWpyzKsC_Qtg",
        "outputId": "fc271b68-8f16-4878-8789-41178f469f2a"
      },
      "source": [
        "results_th = {}\n",
        "\n",
        "l_sum = (lambdas*mults).sum().item()\n",
        "l2_sum = (lambdas**2 * mults).sum().item()\n",
        "dE_dn_preds = (l2_sum / l_sum**2 - 2 * lambdas / l_sum)\n",
        "results_th['dE_dn'] = [float(x) for x in dE_dn_preds]\n",
        "\n",
        "for n in ns_th:\n",
        "  # print(f'predicting for n = {n}')\n",
        "  for k in ks:\n",
        "    exp_params['f_terms'] = {k : 1}\n",
        "    exp_params['n'] = n\n",
        "    results = learning_measure_predictions(net_fns[2], **exp_params)\n",
        "    results_th[str(k) + ',' + '%.3f'%n] = results\n",
        "    with open(main_dir+'/D/hypercube/results_th.json', 'w') as file:\n",
        "      json.dump(results_th, file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
            "  improvement from the last ten iterations.\n",
            "  warnings.warn(msg, RuntimeWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy8sM-S6_Qth"
      },
      "source": [
        "##### Hypercube experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k2GdlZ2_Qth"
      },
      "source": [
        "results_exp = {}\n",
        "\n",
        "for n in ns_exp:\n",
        "  for k in ks:\n",
        "    print(f'predicting for {(k, n)}')\n",
        "    exp_params['f_terms'] = {k : 1}\n",
        "    exp_params['n'] = n\n",
        "    results = learning_measure_statistics(net_fns, **exp_params)\n",
        "    results_exp[str(k) + ',' + str(n)] = results\n",
        "    with open(main_dir+'/D/hypercube/results_exp.json', 'w') as file:\n",
        "      json.dump(results_exp, file)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmW5vDAZx_yq"
      },
      "source": [
        "### Hypersphere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wje8txz6x_yr"
      },
      "source": [
        "d = 3\n",
        "\n",
        "ks = [0, 2, 4, 6, 8]\n",
        "\n",
        "ns_exp = [0, 1, 2, 3, 4, 5, 6, 7]\n",
        "ns_th = list(np.linspace(0, max(ns_exp), 50, endpoint=True))\n",
        "\n",
        "lambdas, mults = hypersphere_eigenvalues(net_fns[2], d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtmEcJrbx_yr"
      },
      "source": [
        "exp_params = {\n",
        "    'domain': 'hypersphere',\n",
        "    'd': d,\n",
        "    'n': None,\n",
        "    'n_test': 10**5,\n",
        "    'f_terms': None,\n",
        "    'g_terms': [],\n",
        "    'n_epochs': 10000,\n",
        "    'lr': .1,\n",
        "    'stop_mse': 10**-5,\n",
        "    'print_every': None,\n",
        "    'n_trials': 100,\n",
        "    'lambdas': lambdas,\n",
        "    'mults': mults,\n",
        "    'seed': 2,\n",
        "    'pred_type': 'both'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgWRmDo9x_yr"
      },
      "source": [
        "##### Hypersphere theory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYEerwAtx_yr",
        "outputId": "fd9bcd7d-96e8-4de7-d75e-a4f04117b863"
      },
      "source": [
        "results_th = {}\n",
        "\n",
        "l_sum = (lambdas*mults).sum().item()\n",
        "l2_sum = (lambdas**2 * mults).sum().item()\n",
        "dE_dn_preds = (l2_sum / l_sum**2 - 2 * lambdas / l_sum)\n",
        "results_th['dE_dn'] = [float(x) for x in dE_dn_preds]\n",
        "\n",
        "for n in ns_th:\n",
        "  # print(f'predicting for n = {n}')\n",
        "  for k in ks:\n",
        "    exp_params['f_terms'] = {k : 1}\n",
        "    exp_params['n'] = n\n",
        "    results = learning_measure_predictions(net_fns[2], **exp_params)\n",
        "    results_th[str(k) + ',' + '%.3f'%n] = results\n",
        "    with open(main_dir+'/D/hypersphere/results_th.json', 'w') as file:\n",
        "      json.dump(results_th, file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
            "  improvement from the last ten iterations.\n",
            "  warnings.warn(msg, RuntimeWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmnGE0w1x_ys"
      },
      "source": [
        "##### Hypersphere experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAjpb6YCx_ys"
      },
      "source": [
        "results_exp = {}\n",
        "\n",
        "for n in ns_exp:\n",
        "  for k in ks:\n",
        "    print(f'predicting for {(k, n)}')\n",
        "    exp_params['f_terms'] = {k : 1}\n",
        "    exp_params['n'] = n\n",
        "    results = learning_measure_statistics(net_fns, **exp_params)\n",
        "    results_exp[str(k) + ',' + str(n)] = results\n",
        "    with open(main_dir+'/D/hypersphere/results_exp.json', 'w') as file:\n",
        "      json.dump(results_exp, file)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNKcTqLbpqmU"
      },
      "source": [
        "## Testing the \"no-free-lunch\" theorem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZscNCPd2UC6"
      },
      "source": [
        "for dir in [main_dir+'/E', main_dir+'/E/circle']:\n",
        "  if not os.path.exists(dir):\n",
        "      os.makedirs(dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlcCwpvMkKK9"
      },
      "source": [
        "net_fn_sets = []\n",
        "net_fn_sets += [get_net_fns(width=500, d_out=1, n_hidden_layers=1)]\n",
        "net_fn_sets += [get_net_fns(width=500, d_out=1, n_hidden_layers=4)]\n",
        "net_fn_sets += [get_net_fns(width=500, d_out=1, n_hidden_layers=1, phi=np.tanh, W_std=1.5, b_std=.1)]\n",
        "net_fn_sets += [get_net_fns(width=500, d_out=1, n_hidden_layers=4, phi=np.tanh, W_std=1.5, b_std=.1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8QYg6ylqKZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19030c90-3cde-4051-899e-3e1061a91ef2"
      },
      "source": [
        "M = 10\n",
        "ns_exp = [3, 6]\n",
        "modes = [(k,'c') for k in range(M//2 + 1)] + [(k,'s') for k in range(1, (M+1)//2)]\n",
        "print(modes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 'c'), (1, 'c'), (2, 'c'), (3, 'c'), (4, 'c'), (5, 'c'), (1, 's'), (2, 's'), (3, 's'), (4, 's')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_cVzJKcqKZk"
      },
      "source": [
        "exp_params = {\n",
        "    'domain': 'circle',\n",
        "    'M': M,\n",
        "    'n': None,\n",
        "    'f_terms': None,\n",
        "    'g_terms': [],\n",
        "    'n_epochs': 10000,\n",
        "    'lr': .5,\n",
        "    'stop_mse': 10**-5,\n",
        "    'print_every': None,\n",
        "    'n_trials': 1,\n",
        "    'seed': 1,\n",
        "    'pred_type': 'both'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6teevfiWp5i1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd7db1f-9a30-453f-b3cd-dd0d50c68975"
      },
      "source": [
        "assert main_dir[-1] == 'E'\n",
        "\n",
        "results_exp = {}\n",
        "\n",
        "for a, net_fns in enumerate(net_fn_sets):\n",
        "  for n in ns_exp:\n",
        "    print(f'testing (a={a}, n={n})')\n",
        "    exp_params['n'] = n\n",
        "\n",
        "    for mode in modes:\n",
        "      exp_params['f_terms'] = {mode : 1}\n",
        "      results_exp[str(a)+','+str(n)+','+str(mode[0])+','+str(mode[1])] = learning_measure_statistics(net_fns, **exp_params)\n",
        "    \n",
        "    with open(main_dir+'/E/circle/results_exp.json', 'w') as file:\n",
        "      json.dump(results_exp, file)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing (a=0, n=3)\n",
            "testing (a=0, n=6)\n",
            "\n",
            "testing (a=1, n=3)\n",
            "testing (a=1, n=6)\n",
            "\n",
            "testing (a=2, n=3)\n",
            "testing (a=2, n=6)\n",
            "\n",
            "testing (a=3, n=3)\n",
            "testing (a=3, n=6)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX-u9LS4HDKX"
      },
      "source": [
        "## Repeating the hypercube experiment at various widths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ythwJw8hHDKX"
      },
      "source": [
        "for dir in [main_dir, main_dir+'/F/hypercube']:\n",
        "  if not os.path.exists(dir):\n",
        "      os.makedirs(dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb6oTPipHDKX"
      },
      "source": [
        "widths = [500, 200, 100, 50, 20, 10]\n",
        "net_fn_sets = {w : get_net_fns(width=w, d_out=1, n_hidden_layers=4) for w in widths}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCli4Zd8HDKX"
      },
      "source": [
        "### Hypercube"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZJbDYfJHDKX"
      },
      "source": [
        "d = 8\n",
        "\n",
        "ks = [0, 1, 3, 8]\n",
        "\n",
        "ns_exp = [0] + [2**i for i in range(d + 1)]\n",
        "ns_th = list(np.linspace(0, 1, 10, endpoint=False)) + list(np.logspace(0, math.log10(2**d), 50))\n",
        "\n",
        "lambdas, mults = hypercube_eigenvalues(net_fn_sets[widths[0]][2], d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR0oiX-JHDKX"
      },
      "source": [
        "exp_params = {\n",
        "    'domain': 'hypercube',\n",
        "    'd': d,\n",
        "    'n': None,\n",
        "    'f_terms': None,\n",
        "    'g_terms': [],\n",
        "    'n_epochs': 5000,\n",
        "    'lr': .1,\n",
        "    'stop_mse': 10**-3,\n",
        "    'print_every': None,\n",
        "    'n_trials': 30,\n",
        "    'lambdas': lambdas,\n",
        "    'mults': mults,\n",
        "    'seed': 1,\n",
        "    'pred_type': 'both'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieb54DINHDKY"
      },
      "source": [
        "##### Hypercube theory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0W8x8RdHDKY",
        "outputId": "154930e8-d584-4bfa-eab7-7aaaa139f953"
      },
      "source": [
        "results_th = {}\n",
        "\n",
        "for n in ns_th:\n",
        "  for k in ks:\n",
        "    # print(f'predicting for n = {n}')\n",
        "    exp_params['f_terms'] = {k : 1}\n",
        "    exp_params['n'] = n\n",
        "    results = learning_measure_predictions(net_fn_sets[widths[0]][2], **exp_params)\n",
        "    results_th[str(k) + ',' + '%.3f'%n] = results\n",
        "    with open(main_dir+'/F/hypercube/results_th.json', 'w') as file:\n",
        "      json.dump(results_th, file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
            "  improvement from the last ten iterations.\n",
            "  warnings.warn(msg, RuntimeWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBzet8i7HDKY"
      },
      "source": [
        "##### Hypercube experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIXuNFmfHDKY"
      },
      "source": [
        "for w in widths:\n",
        "  results_exp = {}\n",
        "  for n in ns_exp:\n",
        "    print(f'predicting for {(w, n)}')\n",
        "    for k in ks:\n",
        "      exp_params['f_terms'] = {k : 1}\n",
        "      exp_params['n'] = n\n",
        "      results = learning_measure_statistics(net_fn_sets[w], **exp_params)\n",
        "      results_exp[str(w) + ',' + str(k) + ',' + str(n)] = results\n",
        "      with open(main_dir+f'/F/hypercube/results_exp_w{w}.json', 'w') as file:\n",
        "        json.dump(results_exp, file)\n",
        "    # print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxry4u8QWFF-"
      },
      "source": [
        "## Generating domain eigenvalues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHLlvDNJWFF-"
      },
      "source": [
        "for dir in [main_dir+'/G']:\n",
        "  if not os.path.exists(dir):\n",
        "      os.makedirs(dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4my7vThWFF-"
      },
      "source": [
        "net_fns = get_net_fns(width=500, d_out=1, n_hidden_layers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCPPYtXzWKjf"
      },
      "source": [
        "M = 256\n",
        "lambdas_c, mults_c = unit_circle_eigenvalues(net_fns[2], M), np.ones(M)\n",
        "\n",
        "d = 8\n",
        "lambdas_h, mults_h = hypercube_eigenvalues(net_fns[2], d)\n",
        "\n",
        "d = 8\n",
        "lambdas_s, mults_s = hypersphere_eigenvalues(net_fns[2], d, k_max=70)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueEuXFq9XFOG"
      },
      "source": [
        "eigenvalues = {\n",
        "    'circle' : [lambdas_c.tolist(), mults_c.tolist()],\n",
        "    'hypercube' : [lambdas_h.tolist(), mults_h.tolist()],\n",
        "    'hypersphere' : [lambdas_s.tolist(), mults_s.tolist()]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D_KrrrGWUHL"
      },
      "source": [
        "with open(main_dir+'/G/eigenvalues.json', 'w') as file:\n",
        "  json.dump(eigenvalues, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiMljbGzRscS"
      },
      "source": [
        "## Examining statistics of $C^{(\\Phi, \\phi)}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0VhJYETXdEv"
      },
      "source": [
        "for dir in [main_dir+'/H']:\n",
        "  if not os.path.exists(dir):\n",
        "      os.makedirs(dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uOIgYf1cJ_f"
      },
      "source": [
        "net_fns = get_net_fns(width=500, d_out=1, n_hidden_layers=4)\n",
        "\n",
        "d = 8\n",
        "lambdas_s, mults_s = hypersphere_eigenvalues(net_fns[2], d, k_max=70)\n",
        "\n",
        "lambdas = []\n",
        "for i in range(7):\n",
        "  lambdas += [lambdas_s[i]]*int(mults_s[i])\n",
        "lambdas = np.array(lambdas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV9uatEPRtXj"
      },
      "source": [
        "def random_C(n, lambdas):\n",
        "  global key\n",
        "  key, subkey1, subkey2 = random.split(key, 3)\n",
        "  Phi = random.normal(subkey1, (len(lambdas), n))\n",
        "  phi = random.normal(subkey2, (n, 1))\n",
        "  Lambda = np.diag(lambdas)\n",
        "  C = 1/(phi.T @ np.linalg.inv(Phi.T @ Lambda @ Phi) @ phi)\n",
        "  return C[1,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqhPALg4TvZ8"
      },
      "source": [
        "def C_stats(n, lambdas, S=10**3):\n",
        "  Cs = np.array([random_C(n, lambdas) for _ in range(S)])\n",
        "  return Cs.mean(), Cs.var()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hxgxFcyS7rp"
      },
      "source": [
        "key = random.PRNGKey(17)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E94IiodmTADd"
      },
      "source": [
        "# M = 2**11\n",
        "# lambdas = np.array([1/(1 + k**2) for k in range(M)])\n",
        "S = 10**3\n",
        "ns = [2**i for i in range(10)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uD_ULsmTNV-"
      },
      "source": [
        "ratios = [(lambda m,v : v/m**2)(*C_stats(n, lambdas, S)).item() for n in ns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "5NulyrefUarH",
        "outputId": "8debe398-e3ad-4140-d9d3-131625de2fbc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5,3))\n",
        "ax.set_xscale('log')\n",
        "ax.set_yscale('log')\n",
        "\n",
        "ax.scatter(ns, ratios, color=(0,.5,.5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fca03f1ec50>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUQAAADGCAYAAACq5fmhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOa0lEQVR4nO3dwYtUZ77G8ecZb/fCgalF4kptNbQIQi/CNN4/oDIXw0yNYWYgens1IzYuDMzSYDazaHJnJzLeCX1RvAONXpEh2JDgQMPFjQvbbFoRsZGraRnQSaAX4yLt8LsLT0/aSlenqk9VvW+d/n4gkHrr1Dm/vGke3nPe857jiBAAQPpB6gIAIBcEIgAUCEQAKBCIAFAgEAGgQCACQOFfUhewkTfffDP27t2bugwAFXPnzp2/RcSO5vYsA9F2Q1JjdHRU8/PzqcsBUDG2H6/XnuUpc0TMRsRkrVZLXQqALSTLQASAFLI8Ze7UzMKCzszN6cnyskZqNU3V65oYG0tdFoABM/CBOLOwoMnZWb1YWZEkPV5e1uTsrCQRigA6MvCnzGfm5v4ZhqterKzozNxcoooADKq+jRBtvyfpp5J+JOlCRPylG/t9srzcUTsAtFJqhGj7ou1ntu82tR+2/cD2ou3TkhQRn0bECUknJb1f5rhrjbSYiW7VDgCtlD1lviTp8NoG29sknZf0rqSDko7ZPrhmk4+K77tiql7X9qGh19q2Dw1pql7v1iEAbBGlAjEibkr6uqn5kKTFiHgUEd9IuiLpiF/5vaTPI+KLMsdda2JsTNONhvbUarKkPbWaphsNJlQAdKwX1xB3SvpyzeclSf8q6QNJ70iq2R6NiE/W+7HtSUmTkjQyMtLWASfGxghAAKX1bVIlIs5JOtfGdtOSpiVpfHyc9xsA6Jte3HbzVNLuNZ93FW1ts92wPb3MTDGAPupFIN6WtN/2PtvDko5Kut7JDljLDCCFsrfdXJZ0S9IB20u2j0fES0mnJN2QdF/S1Yi41+F+GSEC6Dvn/BrS8fHx4PFfALrN9p2IGG9uz3LpHiNEAClkGYhcQwSQQpaByAgRQApZBiIjRAApZBmIAJBCloHIKTOAFLIMRE6ZAaSQZSACQApZBiKnzABSyDIQOWUGkEKWgQgAKRCIAFDI8r3MthuSGqOjo6lLaWlmYUFn5ub0ZHlZI7Wapup1ntoNDLgsR4i5X0OcWVjQ5OysHi8vKyQ9Xl7W5OysZhYWUpcGoIQsAzF3Z+bm9GJl5bW2FysrOjM3l6giAN1AIG7Ckxa3A7VqBzAYCMRNGGlxKt+qHcBgIBA3Yape1/ahodfatg8NaapeT1QRgG7IMhBzX6kyMTam6UZDe2o1WdKeWk3TjQazzMCA450qALacgXqnCgCkQCACQIFABIACgQgABQIRAAp9C0Tbb9m+YPtav44JAJ0oFYi2L9p+ZvtuU/th2w9sL9o+LUkR8Sgijpc5HgD0UtkR4iVJh9c22N4m6bykdyUdlHTM9sGSxwGAnisViBFxU9LXTc2HJC0WI8JvJF2RdKTMcQCgH3pxDXGnpC/XfF6StNP2G7Y/kfS27Q9b/dj2pO152/PPnz/vQXkAsL6+PTE7Ir6SdLKN7aZt/1VSY3h4+Me9rwwAXunFCPGppN1rPu8q2tqW+xOzAVRTLwLxtqT9tvfZHpZ0VNL1TnaQ+9NuAFRT2dtuLku6JemA7SXbxyPipaRTkm5Iui/pakTc62S/jBABpFDqGmJEHGvR/pmkzza730F46x6A6sly6R4jRAApZBmIXEMEkEKWgcgIEUAKWQYiAKSQZSByygwghSwDkVNmAClkGYgAkAKBCACFLAORa4gAUsgyELmG+F0zCwvae/asfvC732nv2bOaWVhIXRJQOX17/Bc2b2ZhQZOzs3qxsiJJery8rMnZWUnSxNhYytKASslyhIjXnZmb+2cYrnqxsqIzc3OJKgKqKctA5Bri65606IdW7QA2J8tA5Bri60Za9EOrdgCbk2Ug4nVT9bq2Dw291rZ9aEhT9XqiioBqYlJlAKxOnJyZm9OT5WWN1GqaqteZUAG6jEAcEBNjYwQg0GOcMgNAIctAZJYZQApZBiKzzABSyDIQASAFAhEACgQiABQIRAAoEIgAUOjbjdm2fyjpPyV9I+l/I2KmX8cGgHaUGiHavmj7me27Te2HbT+wvWj7dNH8C0nXIuKEpJ+XOS4A9ELZU+ZLkg6vbbC9TdJ5Se9KOijpmO2DknZJ+rLY7B8ljwsAXVcqECPipqSvm5oPSVqMiEcR8Y2kK5KOSFrSq1Dc8Li2J23P255//vx5mfIAoCO9mFTZqW9HgtKrINwp6c+Sfmn7j5JmW/04IqYjYjwixnfs2NGD8tAO3uGCrahvkyoR8XdJv25nW9sNSY3R0dHeFoV18Q4XbFW9GCE+lbR7zeddRVvbWMucFu9wwVbVi0C8LWm/7X22hyUdlXS9kx3wtJu0eIcLtqqyt91clnRL0gHbS7aPR8RLSack3ZB0X9LViLjXyX4ZIabFO1ywVZW6hhgRx1q0fybps83ul2uIaU3V669dQ5R4hwu2hiyX7jFCTGtibEzTjYb21GqypD21mqYbDSZUUHmOiNQ1fMeaEeKJhw8fpi4HQMXYvhMR483tjBABoJBlIAJAClkGIrfdAEghy0DklBlAClkGIgCkkGUgcsoMIIUsA5FTZgApZBmIAJACgQgAhSwDkWuIAFLIMhC5hggghb49MRvYyMzCgs7MzenJ8rJGajVN1es8TAJ9RyAiOV5ZgFxkecqMrYVXFiAXBCKS45UFyEWWgcgs89bCKwuQiywDkVnmrWWqXtf2oaHX2nhlAVJgUgXJrU6cMMuM1AhEZGFibIwARHJZnjIDQAoEIgAUCEQAKPQtEG2/ZfuC7Wv9OiYAdKKtQLR90fYz23eb2g/bfmB70fbpjfYREY8i4niZYgGgl9qdZb4k6Q+S/rTaYHubpPOSfiJpSdJt29clbZP0cdPvfxMRz0pXC3QJD5PAetoKxIi4aXtvU/MhSYsR8UiSbF+RdCQiPpb0s24WCXQTD5NAK2WuIe6U9OWaz0tF27psv2H7E0lv2/5wg+0mbc/bnn/+/HmJ8oD18TAJtNK3G7Mj4itJJ9vYbtr2XyU1hoeHf9z7yrDV8DAJtFJmhPhU0u41n3cVbaWxlhm9xMMk0EqZQLwtab/tfbaHJR2VdL0bRfG0G/QSD5NAK+3ednNZ0i1JB2wv2T4eES8lnZJ0Q9J9SVcj4l43imKEiF6aGBvTdKOhPbWaLGlPrabpRoMJFcgRkbqG77DdkNQYHR098fDhw9TlAKgY23ciYry5Pcule4wQAaSQZSACQApZPg9xzSlz6lKArmBlzGDIcoTIKTOqZHVlzOPlZYW+XRkzs7CQujQ0yTIQue0GVcLKmMGRZSAyQkSVsDJmcGQZiECVsDJmcBCIQI+xMmZwZBmIXENElbAyZnBkuVJl1fj4eMzPz6cuA0DFDNRKFQBIgUAEgAIrVYCKYnVM57IcIXIfIlAOq2M2J8tABFAOq2M2h0AEKojVMZtDIAIVxOqYzSEQgQpidczmZBmIrFQBymF1zOawUgXAlsNKFQD4HgQiABQIRAAoEIgAUMhyLTOAwVOFtdN9C0Tb70n6qaQfSboQEX/p17EB9Nbq2unV5YKra6clDVQotnXKbPui7We27za1H7b9wPai7dMb7SMiPo2IE5JOSnp/8yUDyE1V1k63O0K8JOkPkv602mB7m6Tzkn4iaUnSbdvXJW2T9HHT738TEc+Kf/+o+B2AiqjK2um2AjEibtre29R8SNJiRDySJNtXJB2JiI8l/ax5H7Yt6T8kfR4RX7Q6lu1JSZOSNDIy0k55ABIbqdX0eJ3wG7S102VmmXdK+nLN56WirZUPJL0j6Ve2T7baKCKmI2I8IsZ37NhRojwA/VKVtdN9m1SJiHOSzrWzLU/MBgbL6sTJVp5lfipp95rPu4q20iJiVtLs+Pj4iW7sD0DvTYyNDVwANisTiLcl7be9T6+C8Kikf+9GUYwQAXyfXtz32O5tN5cl3ZJ0wPaS7eMR8VLSKUk3JN2XdDUi7pWqpsA7VQBspFfvjMny8V9rRognHj58mLocAJnZe/bsurPae2o1/d9vf/u9vx+ox38xQgSwkV7d95hlIPLEbAAb6dU7Y7IMREaIADbSq/seedoNgIHTq/semVQBsOUwqQIA3yPLQASAFLI8ZV5l+7mkx8XHmqTmaefmtjcl/a0PpW1UQ69/3872G23T6rtO2lP3e9k+73QfZft8o+/bbV9vu0Hr91z+1iVpT0R89+kxETEQ/0ia/r42SfM51NXL37ez/UbbtPquk/bU/V62zzvdR9k+70a/t/j/MFD9nsvf+kb/DNIp82ybbf1WtoZOf9/O9htt0+q7TtpT93s3jt/JPsr2+Ubft9ueus+l6vytt5T1KXOnbM/HOjNH6C36PQ36vfsGaYTYjunUBWxR9Hsa9HuXVWqECABlVG2ECACbRiACQIFABIBCpQPR9g9t/7ft/7I9kbqercL2W7Yv2L6WupatwvZ7xd/5/9j+t9T1DKqBC0TbF20/s323qf2w7Qe2F22fLpp/IelaRJyQ9PO+F1shnfR7RDyKiONpKq2ODvv80+Lv/KSk91PUWwUDF4iSLkk6vLbB9jZJ5yW9K+mgpGO2D+rVmwBX3x39jz7WWEWX1H6/ozsuqfM+/6j4HpswcIEYETclfd3UfEjSYjEy+UbSFUlHJC3pVShKA/jfmpMO+x1d0Emf+5XfS/o8Ir7od61VUZWQ2KlvR4LSqyDcKenPkn5p+4/KY+lT1azb77bfsP2JpLdtf5imtMpq9bf+gaR3JP3K9skUhVVBpZ+YHRF/l/Tr1HVsNRHxlV5dy0KfRMQ5SedS1zHoqjJCfCpp95rPu4o29Bb93n/0eQ9VJRBvS9pve5/tYUlHJV1PXNNWQL/3H33eQwMXiLYvS7ol6YDtJdvHI+KlpFOSbki6L+lqRNxLWWfV0O/9R5/3Hw93AIDCwI0QAaBXCEQAKBCIAFAgEAGgQCACQIFABIACgQgABQIRAAoEIgAU/h+k5JfqSxSxNAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC9Sgw1YU2rx"
      },
      "source": [
        "with open(main_dir+'/H/ratios.json', 'w') as file:\n",
        "  json.dump({'ns':ns, 'ratios':ratios}, file)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}